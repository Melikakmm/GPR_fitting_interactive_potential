{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melikakmm/GPR_fitting_interactive_potential/blob/main/fitpot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-77ac8cba783beb33",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AthWPoKVNG19"
      },
      "source": [
        "# Gaussian Process regression for fitting interatomic potentials\n",
        "\n",
        "## Workshop Aims\n",
        "* Data representation using invariant descriptors\n",
        "* Building covariance matrices for derived quantities - learning from total energy data\n",
        "* Uncertainty analysis of predicted energy values\n",
        "* Optimising hyperparameters\n",
        "* Relaxing geometry using a machine learned potential\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XvfFgVaZNG1_"
      },
      "outputs": [],
      "source": [
        "!alias gcc='gcc-11'\n",
        "!alias cc='gcc-11'\n",
        "!alias g++='g++-11'\n",
        "!alias c++='c++-11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha1Q9lGuNG2A",
        "outputId": "95d22bb3-f146-45eb-b8a9-a91e1f48dee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPy\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.4/959.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from GPy) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from GPy) (1.16.0)\n",
            "Collecting paramz>=0.9.0 (from GPy)\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from GPy) (0.29.36)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from GPy) (1.10.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from paramz>=0.9.0->GPy) (4.4.2)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp310-cp310-linux_x86_64.whl size=3211197 sha256=fed5785de35d6908f4a437b76a659566b978f4538595c2741b2cc2ab52f8b0cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/bd/9f/82ab4216eae088cba864ca0dc1d75699bd4bf6823790fb2f77\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102544 sha256=0d322885a2e9e3ea929ceca915dbfdcc8af64f44ab38f8f24d3c551af99ab32f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/ef/9c/da9ceef7d0ff5287c24365844fc394852c2b79ac3fcf33bf8b\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.10.0 paramz-0.9.5\n"
          ]
        }
      ],
      "source": [
        "pip install GPy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30JyNA_COBs3",
        "outputId": "ecbca26a-e99c-4aaf-a7bf-b401bd55b4e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ase\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase) (1.16.0)\n",
            "Installing collected packages: ase\n",
            "Successfully installed ase-3.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nglview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3_vKBnWOLn_",
        "outputId": "8d77da1f-49a2-4894-a779-b1897ed7bb0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nglview\n",
            "  Downloading nglview-3.0.7.tar.gz (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipywidgets>=7 in /usr/local/lib/python3.10/dist-packages (from nglview) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.10/dist-packages (from nglview) (3.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nglview) (1.23.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7->nglview) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7->nglview) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7->nglview) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7->nglview) (3.6.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7->nglview) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7->nglview)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7->nglview) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7->nglview) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.5.7)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7->nglview) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7->nglview) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7->nglview) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (3.10.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (4.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets>=7->nglview) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.9.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.6.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7->nglview) (2.21)\n",
            "Building wheels for collected packages: nglview\n",
            "  Building wheel for nglview (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nglview: filename=nglview-3.0.7-py3-none-any.whl size=10096145 sha256=e15a44a640ff0f924485488f9f3c94188bb4f1ab5c217109b079a19b2f94427e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/09/68/d0d369f347c8fb4a8668b313744d9e83bb24d5c7060b962825\n",
            "Successfully built nglview\n",
            "Installing collected packages: jedi, nglview\n",
            "Successfully installed jedi-0.19.0 nglview-3.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0925ca393e319102",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "e115a829410846f0b104450e46919a8d"
          ]
        },
        "id": "NML_jfbQNG2B",
        "outputId": "672b6000-d200-4f50-bce4-23d881a1f9c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e115a829410846f0b104450e46919a8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import GPy\n",
        "\n",
        "from ase.io import read\n",
        "import nglview\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-da1e48df809e6488",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3Z8kYbHdNG2B"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d9ebcb163bda0b66",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "yW9tF5-TNG2B"
      },
      "source": [
        "## Part 1\n",
        "### Learning the interaction energy of a single water molecule\n",
        "\n",
        "The quantum mechanical energy of a water molecule - within the Born-Oppenheimer approximation - is a function of the geometry of the molecule, i.e. the Cartesian coordinates $\\mathbf{r}_\\rm{O}$, $\\mathbf{r}_{\\rm H_1}$ and  $\\mathbf{r}_{\\rm H_2}$. Of course, this energy does not depend on the orientation of the water molecule if there is no external field interacting with the molecule.\n",
        "\n",
        "<img src=\"water.png\">\n",
        "\n",
        "We can rewrite the energy function as $E(\\mathbf{r}_{\\rm O},\\mathbf{r}_{\\rm H_1},\\mathbf{r}_{\\rm H_2}) \\equiv E(r_{\\rm OH_1},r_{\\rm OH_2},\\theta_{\\rm HOH})$ where $r_{\\rm OH}$ are the bond lengths and $\\theta_{\\rm HOH}$ the bond angle. This description is invariant to rotations and translations. We also know that the 'label' of the hydrogens is unimportant (i.e. swapping $\\rm H_1$ and $\\rm H_2$ does not change the energy), therefore it is useful to symmetrise the distances.\n",
        "\n",
        "In this exercise, we will use the following data coordinates:\n",
        "* $r_+ = r_{\\rm OH_1} + r_{\\rm OH_2}$\n",
        "* $r_- = (r_{\\rm OH_1} - r_{\\rm OH_2})^2$\n",
        "* $a = \\mathbf{r}_{\\rm OH_1} \\cdot \\mathbf{r}_{\\rm OH_2}$\n",
        "\n",
        "### Question 1\n",
        "\n",
        "**Explain why the descriptor functions $r_+$, $r_-$ and $a$ are invariant to rigid rotations, translations of the molecule and permutations of the hydrogen indices.** [5 marks]\n",
        "\n",
        "**Hint:** For each descriptor element, consider how they change if a rigid geometrical transformation is applied which changes the Cartesian coordinates, but keeps the molecular geometry intact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-e72aabac931c9823",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wYAcDqYZNG2C"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRKwBIo5NG2C"
      },
      "outputs": [],
      "source": [
        "# Read in water configurations\n",
        "water_configs = read(\"water_configs.xyz\", format=\"extxyz\", index=\":\")\n",
        "# There should be 2886 independent water molecules\n",
        "print(len(water_configs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4FzJl0aNG2C"
      },
      "outputs": [],
      "source": [
        "# optional - for visualisation\n",
        "nglview.show_asetraj(water_configs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-aCIb_vNG2C"
      },
      "outputs": [],
      "source": [
        "x = [] # input features\n",
        "y = [] # target values\n",
        "\n",
        "# Calculate descriptor vectors for each molecule and collect target energies\n",
        "for a in water_configs:\n",
        "    p = a.get_positions() # positions: O, H1, H2\n",
        "    rOH1 = # calculate distance OH1, use a.get_distance()\n",
        "    rOH2 = # calculate distances OH2\n",
        "    aHOH = # dot product between the vectors OH1 and OH2, e.g p[1]-p[0]\n",
        "\n",
        "    x.append([(rOH1 + rOH2), (rOH1 - rOH2)**2, aHOH]) # collect descriptor vectors\n",
        "\n",
        "    y.append(a.get_potential_energy()) # QM energy of a water molecule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2265a8aeb3698090",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "PYLU_KMoNG2C"
      },
      "source": [
        "We randomly split the data to a train and test set and then use it to train a Gaussian process regression model using `GPy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOfDaSSaNG2C"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size sets the fraction of the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.9)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)[:, None] # GPy needs a 2D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsZxrr_1NG2D"
      },
      "outputs": [],
      "source": [
        "# input_dim: dimensionality of data points - our descriptor vectors have three elements\n",
        "# variance: range (squared) of the function\n",
        "print(\"Range of input data: {:.2f}\".format(y_train.max()-y_train.min()))\n",
        "# lengthscale: characteristic lengthscale - start with a default of 0.5\n",
        "# ARD: automatic relevance determination - allows separate lengthscales for each three descriptor dimensions\n",
        "\n",
        "kernel = GPy.kern.RBF(input_dim=3, variance=1., lengthscale=10.,ARD=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2f7ef19e25d32937",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2ZyQ87uiNG2D"
      },
      "source": [
        "### Question 2.a\n",
        "\n",
        "**Why is it useful to use 'automatic relevance determination' (separate lengthscales, rather than one for all three dimensions) in this situation?** [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-66c4ed6940a7f439",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wprLogLING2D"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6oJ1dThNG2D"
      },
      "outputs": [],
      "source": [
        "# Generate a Gaussian Process model by adding training data. Start with a small noise parameter.\n",
        "m = GPy.models.GPRegression(X_train, y_train, kernel, noise_var=1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqzI6SoYNG2D"
      },
      "outputs": [],
      "source": [
        "# Optimise the likelihood with respect of the hyperparameters of the model\n",
        "m.optimize_restarts(num_restarts = 10);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9b8e88c2e4d1842e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "O-If9qtlNG2D"
      },
      "source": [
        "### Question 2.b\n",
        "\n",
        "**When optimising the hyperparameters, what do we mean by restarts and why is it useful to do more than one?** [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-1fc45652a8ca50ee",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CAX9e3LuNG2D"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUMFZoTnNG2D"
      },
      "outputs": [],
      "source": [
        "# Print the result of the likelihood optimisation\n",
        "display(m)\n",
        "m.rbf.lengthscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-727aaa09cfd54578",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "uQZ-ah3xNG2D"
      },
      "source": [
        "`m` contains the trained model: a combination of the _prior_ (in the form of the kernel and its hyperparameters, as well as the noise model) and _data_ (in the form of geometrical descriptors and corresponding energy values).\n",
        "\n",
        "### Question 2.c\n",
        "\n",
        "**From the output of the previous cell, what is the noise variance of the optimal model? What does this tell us about the data?** [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-5333023354b78801",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "EbhywnxHNG2E"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD3VCHTWNG2E"
      },
      "outputs": [],
      "source": [
        "# Use the model to predict the energy of water configurations.\n",
        "\n",
        "y_train_predict, y_train_error = m.predict(np.array(X_train)) # predict energies of training configurations\n",
        "y_test_predict, y_test_error =   # predict energies of the test set configurations\n",
        "\n",
        "# root-mean-square error (RMSE)\n",
        "rmse =\n",
        "print(\"RMSE = {:.3f} eV\".format(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-hH9tJ0NG2E"
      },
      "source": [
        "### Question 2.d\n",
        "\n",
        "**Plot graphs to show the correlation of actual and predicted energies, and of the actual and predicted error** [5 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-bff3d60b9fc1fa85",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "AWW-1tnpNG2E"
      },
      "outputs": [],
      "source": [
        "# Plot the correlation of actual and predicted data\n",
        "plt.plot(y_train,y_train_predict,\"s\", label='Train')\n",
        "plt.errorbar(y_test,y_test_predict,yerr=np.sqrt(y_test_error[:,0]),fmt=\".\", label='Test')\n",
        "plt.xlabel('True energies / eV')\n",
        "plt.ylabel('Predicted energies / eV')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the correlation of actual and predicted error\n",
        "plt.plot()\n",
        "plt.xlabel('True error / eV')\n",
        "plt.ylabel('Predicted error / eV')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f8987a36072a90b2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HHH8u1N4NG2E"
      },
      "source": [
        "### Question 3.a\n",
        "\n",
        "**Briefly disucss how accurate the Gaussian Process water model is. How accurate is the error prediction?** [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-ca0013e2d181a889",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "LUuEpWbwNG2E"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e26ca6bc0eb19d40",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vz453wH4NG2E"
      },
      "source": [
        "### Question 3.b\n",
        "\n",
        "We only used 10% of the data for training. By adapting the code above, starting from where we split the data into test and train set, fit further GP models with different fractions (10%, 20%, 40%, 80%) of training data - don't forget to optimise the likelihood. Summarise in a table how the root mean squared error (RMSE) changes. Write a short paragraph about the advantages and disadvantages of using more training data. [5 marks code + 5 marks discussion]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-c11793666609373f",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": false,
        "id": "6mweV4faNG2E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=['train_size', 'RMSE'])\n",
        "\n",
        "df['train_size'] = [0.1, 0.2, 0.4, 0.8]\n",
        "\n",
        "for i, train_size in enumerate(df.train_size):\n",
        "    # split data\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)[:, None]\n",
        "    # create modeel\n",
        "    # optimise\n",
        "    # predict on test set y_test_predict, y_test_error =\n",
        "    rmse =\n",
        "    print(train_size, rmse)\n",
        "    df.iloc[i, 1] = rmse\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-23dadcbd2f915dae",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "zAh2VockNG2E"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-10b8cc67f26c5c71",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "trBOYm1vNG2E"
      },
      "source": [
        "### Optimising the geometry of the water molecule, using a Gaussian Process energy model\n",
        "In the following exercise, we will relax the Cartesian coordinates of a water molecule, in order to find the equilibrium geometry. We will use a wrapper function that generates the symmetrised descriptors and using the GP model, predicts the energy of the water molecule. For simplicity, we use the Nelder-Mead algorithm to find the minimum of the function, as it does not require access to the gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEULYBikNG2F"
      },
      "outputs": [],
      "source": [
        "# This is the wrapper function: Cartesian coordinates -> symmetrised descriptors -> GP\n",
        "def GP_water_energy(x):\n",
        "    _x = np.reshape(x, (3,3)) # Input is a flat array of x,y,z coordinates of three atoms.\n",
        "    r1 = np.linalg.norm(_x[0] - _x[1]) # rOH1\n",
        "    r2 = np.linalg.norm(_x[0] - _x[2]) # rOH2\n",
        "    a = np.dot(_x[0] - _x[1],\n",
        "               _x[0] - _x[2]) # dot product of the two OH vectors\n",
        "    _xx = np.array([[(r1 + r2),\n",
        "                     (r1 - r2)**2,\n",
        "                     a]]) # symmetrised descriptor (see above)\n",
        "    res = m.predict(_xx)[0][0][0] # GP prediction\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-7cfd75ac56214a9a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ECivSvXbNG2F"
      },
      "source": [
        "We start from a not-too crazy initial condition, and relax the position of all atoms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fY61KSdNG2F"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "x0 = np.array([0,0,0,       # Oxygen atom\n",
        "               1.2,0,0,     # 1st hydrogen atom\n",
        "               -0.5,0.7,0]) # 2nd hydrogen atom\n",
        "\n",
        "res = minimize(GP_water_energy, # function to minimise\n",
        "               x0,              # initial condition\n",
        "               method='nelder-mead',\n",
        "               options={\"maxiter\":1000, # number of iterations in the minimiser\n",
        "                        \"fatol\":1e-6    # stopping criterion (tolerance)\n",
        "                       })\n",
        "# res.x contains the final configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0YjtYs4NG2F"
      },
      "outputs": [],
      "source": [
        "# We transform the Cartesian coordinates into bond lengths and the bond angle,\n",
        "# for easier interpretation\n",
        "\n",
        "_x = np.reshape(res.x, (3, 3))\n",
        "r1 =\n",
        "r2 =\n",
        "a =\n",
        "print(\"r1 = {:.3f} A\\nr2 = {:.3f} A\\nangle = {:.1f} degrees\".format(r1,r2,np.rad2deg(np.arccos(a))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ae4a2b03b04c71c0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9zTWfY3uNG2F"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Inspect the resulting water geometry. How realistic is it? Compare the geometrical parameters to literature (experimental and/or theoretical) values.** [5 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-d9b24bcfc83519b6",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CbThIDWBNG2F"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-42c1756da9bd0e5a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AsA7ZakmNG2F"
      },
      "source": [
        "### Extension question (not assessed)\n",
        "Try different kernels `GPy.kern.` in the Gaussian Process regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-d82eaef8b9dc228d",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "C7Sugl9hNG2F"
      },
      "outputs": [],
      "source": [
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3eeaf2b2a8e5170b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OvFWZWm0NG2F"
      },
      "source": [
        "## Part 2\n",
        "### Inferring a pair interaction model based on total energy information\n",
        "\n",
        "For certain types of atomic systems, the total, inherently many-body interaction energy may be approximated by pair interaction terms: $E(\\mathbf{r}_1, \\mathbf{r}_2, \\ldots \\mathbf{r}_N) \\approx \\sum^N_{i<j} E_2(r_{ij})$, where the system consists of $N$ atoms with Cartesian coordinates $\\mathbf{r}_1, \\mathbf{r}_2, \\ldots \\mathbf{r}_N$. $E_2$ is a function of interatomic distances $r_{ij}$. Example where this works well are noble gases or certain types of metals.\n",
        "\n",
        "In this part of the workshop, we will study a toy problem, where the total interaction energy consists explicitly of two-body terms, and the aim of the workshop is to recover the original model. We will use configurations of clusters of 12-19 atoms, and the interaction energy (the underlying function we are trying to fit) will be the Lennard-Jones model for the total energy\n",
        "\n",
        "$$\n",
        "E_2^{LJ}(r_{ij}) = 4\\left(\\frac1{r_{ij}^{12}} - \\frac1{r_{ij}^6} \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sz49yfcNG2G"
      },
      "outputs": [],
      "source": [
        "# We load the cluster configurations\n",
        "cluster_trajectory = read(\"clusters.xyz\", index=\":\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJNC0DKBNG2G"
      },
      "outputs": [],
      "source": [
        "# optional\n",
        "nglview.show_asetraj(cluster_trajectory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XQP8Bc-NG2G"
      },
      "outputs": [],
      "source": [
        "# For each cluster, we calculate the total energy and collect it in cluster_energy\n",
        "from ase.calculators.lj import LennardJones\n",
        "p = LennardJones()\n",
        "\n",
        "cluster_energy = []\n",
        "for a in cluster_trajectory:\n",
        "    a.set_calculator(p)\n",
        "    cluster_energy.append(a.get_potential_energy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvZx2xRjNG2G"
      },
      "outputs": [],
      "source": [
        "# We split the data in train and test set.\n",
        "# You may adjust the ratio by varying \"test_size\".\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cluster_train, cluster_test, cluster_energy_train, cluster_energy_test = train_test_split(\n",
        "    cluster_trajectory, cluster_energy, test_size=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e8768a59593973d9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "28lWfSfsNG2G"
      },
      "source": [
        "The model we use for the total energy is\n",
        "\n",
        "$$E = \\sum_{i<j} {\\mathcal GP}(r_{ij}).$$\n",
        "\n",
        "To fit the GP, we need to obtain all pair-wise distances in each configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7WTcFRFNG2G"
      },
      "outputs": [],
      "source": [
        "from ase.neighborlist import neighbor_list\n",
        "\n",
        "def get_distances(atoms_array,cutoff=3.0):\n",
        "    distances = []\n",
        "    for a in atoms_array:\n",
        "        i, j, d = neighbor_list('ijd', a, cutoff)\n",
        "        d = d[i < j]  # We exclude duplicates\n",
        "        distances.append(d)\n",
        "    return distances # List of list of distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUbvLQA8NG2G"
      },
      "outputs": [],
      "source": [
        "distances_train = get_distances(cluster_train)\n",
        "distances_test ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f2ae07101f4f3709",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "51-BejjXNG2G"
      },
      "source": [
        "The target data is the sum of Gaussian Process models. We need to find the covariance of total energies: if the covariance of two pair interactions terms is $k(r,r')$, the covariance of two total energies of two configurations $A$ and $B$ is the sum of covariance functions:\n",
        "\n",
        "$$\\langle E_A E_B \\rangle = \\sum_{ij \\in A, i'j' \\in B} k(r_{ij},r_{i'j'})$$\n",
        "\n",
        "The following class implements this idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "p-dHtkSENG2G"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "class SumGP:\n",
        "    \"\"\"Class implementing a sum Gaussian Process\"\"\"\n",
        "\n",
        "    def __init__(self, length_scale=1.0, function_range=1.0, error=0.1):\n",
        "        \"\"\"Initialise the class with the GP hyperparameters\"\"\"\n",
        "        self.length_scale = length_scale\n",
        "        self.function_range = function_range\n",
        "        self.error = error\n",
        "\n",
        "    def update_covariance(self):\n",
        "        \"\"\"Update the covariance matrix\"\"\"\n",
        "        self.covariance = self.sum_covariance(self.training_data,self.training_data)\n",
        "        self.covariance += np.eye(len(self.covariance))*self.error**2\n",
        "\n",
        "    def update_weights(self):\n",
        "        \"\"\"Update the GP model weights\"\"\"\n",
        "        self.weights = np.linalg.solve(self.covariance,self.training_target)\n",
        "\n",
        "    def update_gp(self):\n",
        "        \"\"\"Update the covariance and the GP model weights\"\"\"\n",
        "        self.update_covariance()\n",
        "        self.update_weights()\n",
        "\n",
        "    def set_training_data(self,distances,energies):\n",
        "        \"\"\"Add training data and perform the fit\"\"\"\n",
        "        self.training_data = distances\n",
        "        self.training_target = energies\n",
        "        self.update_gp()\n",
        "\n",
        "    def set_parameters(self,length_scale=None,function_range=None,error=None):\n",
        "        \"\"\"Update GP hyperparameters\"\"\"\n",
        "        changed = False\n",
        "        if length_scale is not None:\n",
        "            self.length_scale = length_scale\n",
        "            changed = True\n",
        "        if function_range is not None:\n",
        "            self.function_range = function_range\n",
        "            changed = True\n",
        "        if error is not None:\n",
        "            self.error = error\n",
        "            changed = True\n",
        "        if changed:\n",
        "            self.update_gp()\n",
        "\n",
        "    def predict(self,distances, do_variance=False, do_covariance=False):\n",
        "        \"\"\"\n",
        "        Predicts total energy for a set of pairwise distances,\n",
        "        optionally with variances\n",
        "        \"\"\"\n",
        "        k = self.sum_covariance(distances,self.training_data)\n",
        "        mean = np.dot(k,self.weights)\n",
        "        res = {\"mean\":mean}\n",
        "        if do_variance:\n",
        "            variance = []\n",
        "            for _d,_k in zip(distances,k):\n",
        "                variance.append(self.error**2+\n",
        "                    self.sum_covariance([_d],[_d])[0,0] -\n",
        "                           np.dot(_k, np.linalg.solve(self.covariance,_k))\n",
        "                )\n",
        "            res[\"variance\"] = variance\n",
        "\n",
        "        if do_covariance:\n",
        "            covariance = self.sum_covariance(distances,distances)\n",
        "            res[\"covariance\"] = ( np.eye(len(distances))*self.error**2 +\n",
        "                                 covariance - np.dot(k,np.linalg.solve(self.covariance,k.T)) )\n",
        "\n",
        "        return res\n",
        "\n",
        "    def sum_covariance(self, d1, d2):\n",
        "        \"\"\"Sum covariance function\"\"\"\n",
        "        covariance = []\n",
        "        for i, _d1 in enumerate(d1):\n",
        "            _c_row = []\n",
        "            for j, _d2 in enumerate(d2):\n",
        "                distance_matrix = cdist(\n",
        "                    np.array(_d1)[:,None],\n",
        "                    np.array(_d2)[:,None],\n",
        "                    'euclidean')\n",
        "\n",
        "                _c = np.sum(self.function_range**2*np.exp(\n",
        "                            -0.5*distance_matrix**2/self.length_scale**2))\n",
        "                _c_row.append(_c)\n",
        "            covariance.append(_c_row)\n",
        "        covariance = np.array(covariance)\n",
        "        return covariance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-bb4d8a8eac70c4a2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "f-3J2O0JNG2H"
      },
      "source": [
        "We now use this class to build a Gaussian Process regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4pGrap3NG2H"
      },
      "outputs": [],
      "source": [
        "# Initialise the GP with hyperparameters\n",
        "sum_gp = SumGP(length_scale=0.25, error=0.5, function_range=5.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2b3BvlUNG2H"
      },
      "outputs": [],
      "source": [
        "# Add data and fit the model\n",
        "sum_gp.set_training_data(distances_train,cluster_energy_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3a9ddec6e2080df2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8O9SKoH9NG2H"
      },
      "source": [
        "### Optimising the hyperparameters\n",
        "To find the optimal hyperparameters (`length_scale`, `error` and `function_range`) we can try maximising the likelihood of the model:\n",
        "\n",
        "$$\n",
        "\\log L = -\\frac{1}{2} \\mathbf{y}^T \\mathbf{K}^{-1} \\mathbf{y} - \\frac{1}{2} \\log |\\mathbf{K}| - \\frac{n}{2} \\log 2 \\pi$$\n",
        "\n",
        "Remember, the two main components of this expression balance the goodness of the fit (first term) and the complexity of the model (second term).\n",
        "\n",
        "### Question 5.a\n",
        "\n",
        "Implement a log likelihood function for the `SumGP` class using the template provided below. Use the numpy function [np.linalg.slogdet](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.slogdet.html) to compute the log of the determinent of the covariance matrix. For the first term of the log likelihood expression, notice that $\\mathbf{K}^{-1} \\mathbf{y} = \\mathbf{w}$, the fitted weights of the model, stored as `self.weights` in the `SumGP` class. [10 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-09fb5482338e98b8",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "flLiO0UCNG2H"
      },
      "outputs": [],
      "source": [
        "def get_likelihood(self):\n",
        "    \"\"\"Calculate GP likelihood\"\"\"\n",
        "\n",
        "    res = 0.0\n",
        "    ### BEGIN SOLUTION\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return res\n",
        "\n",
        "SumGP.get_likelihood = get_likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG5U0ZGdNG2H"
      },
      "source": [
        "### Question 5.b\n",
        "\n",
        "Compute the log likelihood as a function of the `length_scale` hyperparameter. Plot the results, and determine the optimal parameter, given the other two hyperparameters remain fixed. [10 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-d5bc30f0c6902ed0",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "uasiADybNG2H"
      },
      "outputs": [],
      "source": [
        "sum_gp =\n",
        "# Add data and fit the model\n",
        "\n",
        "length_scale_array = # np.linspace()\n",
        "likelihood_array = []\n",
        "for _l in length_scale_array:\n",
        "    sum_gp.set_parameters(length_scale=_l)\n",
        "    likelihood_array.append(sum_gp.get_likelihood())\n",
        "\n",
        "plt.plot()\n",
        "plt.xlabel('Length scale')\n",
        "plt.ylabel('Log likelihood');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-77f1a920c0092db4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2ZksF87rNG2H"
      },
      "source": [
        "### Question 6.a\n",
        "\n",
        "Set the `length_scale` hyperparameter to the optimal value you found above, and plot the two-body interatomic potential model as a function of interatomic distances, with error bars, and compare it with the known solution, the Lennard-Jones model. You need to set the range of distances where you want to inspect the model - start from short distances and go beyond the cutoff (3.0) we used. [10 marks]\n",
        "\n",
        "Here is some sample code to do predictions to get you started\n",
        "\n",
        "```python\n",
        "# Predict pair interaction energies using the GP model\n",
        "r_min = ...\n",
        "r_max = ...\n",
        "r_test = np.linspace(r_min,r_max)[:,None]\n",
        "test_gp = sum_gp.predict(r_test,do_variance=True,do_covariance=True)\n",
        "e_test_gp = test_gp[\"mean\"]\n",
        "v_test_gp = test_gp[\"variance\"]\n",
        "c_test_gp = test_gp[\"covariance\"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-5f19d3acca286b61",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UccM9HIZNG2H"
      },
      "outputs": [],
      "source": [
        "sum_gp.set_parameters(length_scale=)\n",
        "\n",
        "# Lennard-Jones model - the target of the GP model\n",
        "e_test_lj = # function of r_test\n",
        "\n",
        "# Predict pair interaction energies using the GP model\n",
        "test_gp = sum_gp.predict(r_test,do_variance=True,do_covariance=True)\n",
        "e_test_gp = test_gp[\"mean\"]\n",
        "v_test_gp = test_gp[\"variance\"]\n",
        "c_test_gp = test_gp[\"covariance\"]\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(r_test,e_test_lj)\n",
        "plt.errorbar(r_test,e_test_gp,yerr=np.sqrt(v_test_gp))\n",
        "plt.ylim([-1.2,4])\n",
        "plt.xlabel('Distance $r_{ij}$')\n",
        "plt.ylabel('Energy / eV')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms_TMNRONG2H"
      },
      "source": [
        "### Question 6.b\n",
        "\n",
        "Inspect the predicted error. Identify the domains where the predicted error is large - what is the reason for this? [10 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e742c8decc5b3a46",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "Nqs6umyoNG2I"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c410a5aae7969a0d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WJKRbhmwNG2I"
      },
      "source": [
        "### Question 6.c\n",
        "\n",
        "In the code cell below, using the `np.random.multivariate_normal` function (as seen in the lecture), with `test_gp[\"mean\"]` as the mean and `test_gp[\"covariance\"]` as the covariance, where `test_gp` is the result of calling `sum_gp.predict()`), draw samples from the posterior. Plot the results together with the known target function (Lennard-Jones pairwise interactions). Looking at these samples, how appropriate is our prior (squared exponential kernel)? Which feature of the Lennard-Jones model is causing problems? [5 marks code + 5 marks discussion]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-565f12e6502c715f",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tcsAGNU_NG2I"
      },
      "outputs": [],
      "source": [
        "N_sample = 5\n",
        "\n",
        "for i in range(N_sample):\n",
        "    s_test_gp = # np.random.multivariate_normal()\n",
        "    plt.plot(r_test, s_test_gp, 'r--')\n",
        "plt.plot(r_test,e_test_lj,\"k-\")\n",
        "plt.ylim([-1.2,4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-812b5ff91b18962b",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "b5_Q8xsKNG2I"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f026710554e4f666",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "p8C_6NfXNG2I"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Adapt the code used above to predict GP energies (i.e., using `sum_gp.predict()`), evaluate the GP model on the test set `distances_test` we generated by splitting the original data set. Plot the correlation of the target energy and the prediction, with error bars. [5 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-61e8427026eead65",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VlHQrpp6NG2I"
      },
      "outputs": [],
      "source": [
        "cluster_gp = sum_gp.predict(distances_test, do_variance=True)\n",
        "cluster_energy_predict =\n",
        "cluster_energy_variance =\n",
        "\n",
        "plt.errorbar(cluster_energy_test, cluster_energy_predict,\n",
        "             yerr=np.sqrt(cluster_energy_variance),fmt=\".\")\n",
        "plt.xlabel('True energy / eV')\n",
        "plt.ylabel('Predicted energy / eV');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-21f361e0d3889f8a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Du708POuNG2I"
      },
      "source": [
        "### Extension  question (not assessed)\n",
        "\n",
        "Instead of the squared exponential kernel, implement another kernel (e.g. the exponential kernel $k(r,r') = \\exp ( |r-r'| / l)$ or any other) in the `SumGP` class. Does it represent a better prior than the squared exponential kernel?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-5336ac29a70a74b5",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dlQA0L_-NG2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e115a829410846f0b104450e46919a8d": {
          "model_module": "nglview-js-widgets",
          "model_name": "ColormakerRegistryModel",
          "model_module_version": "3.0.7",
          "state": {
            "_dom_classes": [],
            "_model_module": "nglview-js-widgets",
            "_model_module_version": "3.0.7",
            "_model_name": "ColormakerRegistryModel",
            "_msg_ar": [],
            "_msg_q": [],
            "_ready": false,
            "_view_count": null,
            "_view_module": "nglview-js-widgets",
            "_view_module_version": "3.0.7",
            "_view_name": "ColormakerRegistryView",
            "layout": "IPY_MODEL_66e892682abb4dadb2de2bb904971b4f"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}